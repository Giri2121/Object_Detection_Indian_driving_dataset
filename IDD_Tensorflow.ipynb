{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled14.ipynb","provenance":[],"authorship_tag":"ABX9TyOD/H5WFjmPQZ3vmrqM3dq5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0mx7dqVdKghV","executionInfo":{"status":"ok","timestamp":1643476255803,"user_tz":-330,"elapsed":23020,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"bbc2d17a-1241-471c-cd14-d9794fa557ed"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"bIAidAK7I7uR","executionInfo":{"status":"ok","timestamp":1643476261818,"user_tz":-330,"elapsed":2965,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0GkOP2KIKuC9","executionInfo":{"status":"ok","timestamp":1643476263850,"user_tz":-330,"elapsed":437,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"164ad4fa-6f23-4a56-fcf0-44121e40f243"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Jan 29 17:11:03 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/tensorflow/models.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zoyabz7oI7rc","executionInfo":{"status":"ok","timestamp":1643476294413,"user_tz":-330,"elapsed":24255,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"862410a6-61ea-4aa2-e133-f7293392cab1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 68642, done.\u001b[K\n","remote: Total 68642 (delta 0), reused 0 (delta 0), pack-reused 68642\u001b[K\n","Receiving objects: 100% (68642/68642), 577.01 MiB | 28.10 MiB/s, done.\n","Resolving deltas: 100% (48361/48361), done.\n"]}]},{"cell_type":"code","source":["cd /content/models/research"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkIGnPGQI7oe","executionInfo":{"status":"ok","timestamp":1643476299017,"user_tz":-330,"elapsed":448,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"8ff908f0-b2c3-44dd-ceff-d5de4fd6438e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}]},{"cell_type":"code","source":["!protoc object_detection/protos/*.proto --python_out=."],"metadata":{"id":"63v9RW6tI7lT","executionInfo":{"status":"ok","timestamp":1643476301500,"user_tz":-330,"elapsed":571,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/cocodataset/cocoapi.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edmdSJpyI7ir","executionInfo":{"status":"ok","timestamp":1643476305619,"user_tz":-330,"elapsed":977,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"d85c81a7-a19b-4bec-d9ba-2084d2a961a1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'cocoapi'...\n","remote: Enumerating objects: 975, done.\u001b[K\n","remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n","Receiving objects: 100% (975/975), 11.72 MiB | 21.59 MiB/s, done.\n","Resolving deltas: 100% (576/576), done.\n"]}]},{"cell_type":"code","source":["cd cocoapi/PythonAPI"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zt7be_UAI7gP","executionInfo":{"status":"ok","timestamp":1643476312801,"user_tz":-330,"elapsed":436,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"babe4032-a093-483b-aa95-279b1f66814d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research/cocoapi/PythonAPI\n"]}]},{"cell_type":"code","source":["!make"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HRDTaoe0I7dL","executionInfo":{"status":"ok","timestamp":1643476320588,"user_tz":-330,"elapsed":6133,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"d530da87-80d5-416b-b81d-ff512615c155"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["python setup.py build_ext --inplace\n","running build_ext\n","cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n","/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n","  tree = Parsing.p_module(s, pxd, full_module_name)\n","building 'pycocotools._mask' extension\n","creating build\n","creating build/common\n","creating build/temp.linux-x86_64-3.7\n","creating build/temp.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n","       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n","                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n","                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n","   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n","   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n","                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n","     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n","                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n","       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n","                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n","rm -rf build\n"]}]},{"cell_type":"code","source":["cp -r pycocotools /content/models/research"],"metadata":{"id":"xLByc0iTI7ag","executionInfo":{"status":"ok","timestamp":1643476324695,"user_tz":-330,"elapsed":317,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["cd /content/models/research"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ueyWpChI7Xt","executionInfo":{"status":"ok","timestamp":1643476343127,"user_tz":-330,"elapsed":325,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"02fc51f9-9990-42d1-effb-6d1d012b81d0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}]},{"cell_type":"code","source":["cp object_detection/packages/tf2/setup.py ."],"metadata":{"id":"8iA-7ATII7Uz","executionInfo":{"status":"ok","timestamp":1643476345638,"user_tz":-330,"elapsed":409,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["!python -m pip install --use-feature=2020-resolver ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqAIM7YBI7Nz","executionInfo":{"status":"ok","timestamp":1643476393975,"user_tz":-330,"elapsed":45616,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"e5538a22-887d-437b-8f87-08ae9052739a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n","Processing /content/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.35.0-cp37-cp37m-manylinux2010_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.26)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 47.9 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 35.2 MB/s \n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n","\u001b[K     |████████████████████████████████| 23.1 MB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n","Collecting tensorflow-text>=2.7.0\n","  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 36.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 45.6 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 40.9 MB/s \n","\u001b[?25hCollecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 9.4 MB/s \n","\u001b[?25hCollecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 9.7 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n","\u001b[K     |████████████████████████████████| 47.7 MB 73 kB/s \n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 37.4 MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.10)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 43.1 MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.23.1)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (12.0.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.43.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[?25hCollecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 46.7 MB/s \n","\u001b[?25hCollecting orjson<4.0\n","  Downloading orjson-3.6.6-cp37-cp37m-manylinux_2_24_x86_64.whl (245 kB)\n","\u001b[K     |████████████████████████████████| 245 kB 45.6 MB/s \n","\u001b[?25hCollecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.19.9-py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 3.2 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 47.3 MB/s \n","\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","\u001b[K     |████████████████████████████████| 508 kB 48.5 MB/s \n","\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Collecting protobuf>=3.12.0\n","  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 44.7 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.10)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.6.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1684828 sha256=2be50a964d2959f5acb96f54a7f4828e5d6d680b88a75c1770267b004d1f9660\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-0x13mirm/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=58af25a5bbb413a5da27e6454b2b886b278059567f53948456844b77ab892826\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=af0cba47fb3f56ede626bb54b3c9f32707e2c1d595ab8c9422e4dc2c7be3be40\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=71257c3bcbbccad24d71a94d45debc9ecb06a66aa9e45518f0443888df821cdd\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=2d4db075557ba86082e10e7c06cafb528629de2228797c0afa29e28a83711c17\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n","Installing collected packages: requests, protobuf, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.0.1\n","    Uninstalling pymongo-4.0.1:\n","      Successfully uninstalled pymongo-4.0.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.35.0 avro-python3-1.10.2 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.9 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.62 orjson-3.6.6 portalocker-2.3.2 proto-plus-1.19.9 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-6.0 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.15.0 tensorflow-io-0.23.1 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 tf-models-official-2.7.0 tf-slim-1.1.0\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"cOEDcWHLI7Km","executionInfo":{"status":"ok","timestamp":1643476412217,"user_tz":-330,"elapsed":329,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"0cf9ef98-dcbc-4829-e97f-99c21fc5dcea"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/models/research'"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["!python object_detection/builders/model_builder_tf2_test.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQjHn2vaJ6ZY","executionInfo":{"status":"ok","timestamp":1643476466526,"user_tz":-330,"elapsed":42651,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"7a1b1480-a5d1-43b2-8d42-8f941ff224dd"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Running tests under Python 3.7.12: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2022-01-29 17:13:50.978769: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","W0129 17:13:51.455191 140427498850176 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.26s\n","I0129 17:13:51.785644 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.26s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.66s\n","I0129 17:13:52.446732 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.66s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n","I0129 17:13:52.790132 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n","I0129 17:13:53.108965 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.39s\n","I0129 17:13:55.502053 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.39s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0129 17:13:55.503328 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I0129 17:13:55.531148 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0129 17:13:55.549543 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0129 17:13:55.568260 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n","I0129 17:13:55.695351 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n","I0129 17:13:55.820400 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n","I0129 17:13:55.947548 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n","I0129 17:13:56.083669 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n","I0129 17:13:56.214261 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0129 17:13:56.249568 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0129 17:13:56.484538 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0129 17:13:56.484746 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0129 17:13:56.484859 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0129 17:13:56.488744 140427498850176 efficientnet_model.py:147] round_filter input=32 output=32\n","I0129 17:13:56.518661 140427498850176 efficientnet_model.py:147] round_filter input=32 output=32\n","I0129 17:13:56.518795 140427498850176 efficientnet_model.py:147] round_filter input=16 output=16\n","I0129 17:13:56.598942 140427498850176 efficientnet_model.py:147] round_filter input=16 output=16\n","I0129 17:13:56.599148 140427498850176 efficientnet_model.py:147] round_filter input=24 output=24\n","I0129 17:13:56.793588 140427498850176 efficientnet_model.py:147] round_filter input=24 output=24\n","I0129 17:13:56.793797 140427498850176 efficientnet_model.py:147] round_filter input=40 output=40\n","I0129 17:13:56.980757 140427498850176 efficientnet_model.py:147] round_filter input=40 output=40\n","I0129 17:13:56.980965 140427498850176 efficientnet_model.py:147] round_filter input=80 output=80\n","I0129 17:13:57.441940 140427498850176 efficientnet_model.py:147] round_filter input=80 output=80\n","I0129 17:13:57.442230 140427498850176 efficientnet_model.py:147] round_filter input=112 output=112\n","I0129 17:13:57.746284 140427498850176 efficientnet_model.py:147] round_filter input=112 output=112\n","I0129 17:13:57.746485 140427498850176 efficientnet_model.py:147] round_filter input=192 output=192\n","I0129 17:13:58.148081 140427498850176 efficientnet_model.py:147] round_filter input=192 output=192\n","I0129 17:13:58.148353 140427498850176 efficientnet_model.py:147] round_filter input=320 output=320\n","I0129 17:13:58.244570 140427498850176 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0129 17:13:58.284965 140427498850176 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0129 17:13:58.350353 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0129 17:13:58.350612 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n","I0129 17:13:58.350746 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n","I0129 17:13:58.352856 140427498850176 efficientnet_model.py:147] round_filter input=32 output=32\n","I0129 17:13:58.372358 140427498850176 efficientnet_model.py:147] round_filter input=32 output=32\n","I0129 17:13:58.372503 140427498850176 efficientnet_model.py:147] round_filter input=16 output=16\n","I0129 17:13:58.534284 140427498850176 efficientnet_model.py:147] round_filter input=16 output=16\n","I0129 17:13:58.534539 140427498850176 efficientnet_model.py:147] round_filter input=24 output=24\n","I0129 17:13:58.853180 140427498850176 efficientnet_model.py:147] round_filter input=24 output=24\n","I0129 17:13:58.853373 140427498850176 efficientnet_model.py:147] round_filter input=40 output=40\n","I0129 17:13:59.155766 140427498850176 efficientnet_model.py:147] round_filter input=40 output=40\n","I0129 17:13:59.155992 140427498850176 efficientnet_model.py:147] round_filter input=80 output=80\n","I0129 17:13:59.553292 140427498850176 efficientnet_model.py:147] round_filter input=80 output=80\n","I0129 17:13:59.553513 140427498850176 efficientnet_model.py:147] round_filter input=112 output=112\n","I0129 17:13:59.964777 140427498850176 efficientnet_model.py:147] round_filter input=112 output=112\n","I0129 17:13:59.965018 140427498850176 efficientnet_model.py:147] round_filter input=192 output=192\n","I0129 17:14:00.470251 140427498850176 efficientnet_model.py:147] round_filter input=192 output=192\n","I0129 17:14:00.470455 140427498850176 efficientnet_model.py:147] round_filter input=320 output=320\n","I0129 17:14:00.668596 140427498850176 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0129 17:14:00.720935 140427498850176 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0129 17:14:00.798351 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0129 17:14:00.798541 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n","I0129 17:14:00.798673 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n","I0129 17:14:00.801107 140427498850176 efficientnet_model.py:147] round_filter input=32 output=32\n","I0129 17:14:00.822077 140427498850176 efficientnet_model.py:147] round_filter input=32 output=32\n","I0129 17:14:00.822233 140427498850176 efficientnet_model.py:147] round_filter input=16 output=16\n","I0129 17:14:00.969511 140427498850176 efficientnet_model.py:147] round_filter input=16 output=16\n","I0129 17:14:00.969742 140427498850176 efficientnet_model.py:147] round_filter input=24 output=24\n","I0129 17:14:01.265114 140427498850176 efficientnet_model.py:147] round_filter input=24 output=24\n","I0129 17:14:01.265370 140427498850176 efficientnet_model.py:147] round_filter input=40 output=48\n","I0129 17:14:01.562516 140427498850176 efficientnet_model.py:147] round_filter input=40 output=48\n","I0129 17:14:01.562770 140427498850176 efficientnet_model.py:147] round_filter input=80 output=88\n","I0129 17:14:02.000913 140427498850176 efficientnet_model.py:147] round_filter input=80 output=88\n","I0129 17:14:02.001164 140427498850176 efficientnet_model.py:147] round_filter input=112 output=120\n","I0129 17:14:02.415547 140427498850176 efficientnet_model.py:147] round_filter input=112 output=120\n","I0129 17:14:02.415846 140427498850176 efficientnet_model.py:147] round_filter input=192 output=208\n","I0129 17:14:03.115071 140427498850176 efficientnet_model.py:147] round_filter input=192 output=208\n","I0129 17:14:03.115296 140427498850176 efficientnet_model.py:147] round_filter input=320 output=352\n","I0129 17:14:03.303268 140427498850176 efficientnet_model.py:147] round_filter input=1280 output=1408\n","I0129 17:14:03.347453 140427498850176 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0129 17:14:03.427528 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0129 17:14:03.427739 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n","I0129 17:14:03.427855 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n","I0129 17:14:03.429819 140427498850176 efficientnet_model.py:147] round_filter input=32 output=40\n","I0129 17:14:03.448765 140427498850176 efficientnet_model.py:147] round_filter input=32 output=40\n","I0129 17:14:03.448899 140427498850176 efficientnet_model.py:147] round_filter input=16 output=24\n","I0129 17:14:03.593758 140427498850176 efficientnet_model.py:147] round_filter input=16 output=24\n","I0129 17:14:03.593998 140427498850176 efficientnet_model.py:147] round_filter input=24 output=32\n","I0129 17:14:03.885538 140427498850176 efficientnet_model.py:147] round_filter input=24 output=32\n","I0129 17:14:03.885751 140427498850176 efficientnet_model.py:147] round_filter input=40 output=48\n","I0129 17:14:04.173338 140427498850176 efficientnet_model.py:147] round_filter input=40 output=48\n","I0129 17:14:04.173543 140427498850176 efficientnet_model.py:147] round_filter input=80 output=96\n","I0129 17:14:04.649351 140427498850176 efficientnet_model.py:147] round_filter input=80 output=96\n","I0129 17:14:04.649549 140427498850176 efficientnet_model.py:147] round_filter input=112 output=136\n","I0129 17:14:05.150648 140427498850176 efficientnet_model.py:147] round_filter input=112 output=136\n","I0129 17:14:05.150873 140427498850176 efficientnet_model.py:147] round_filter input=192 output=232\n","I0129 17:14:05.757384 140427498850176 efficientnet_model.py:147] round_filter input=192 output=232\n","I0129 17:14:05.757620 140427498850176 efficientnet_model.py:147] round_filter input=320 output=384\n","I0129 17:14:05.951022 140427498850176 efficientnet_model.py:147] round_filter input=1280 output=1536\n","I0129 17:14:05.986603 140427498850176 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0129 17:14:06.073455 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0129 17:14:06.073711 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n","I0129 17:14:06.073826 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0129 17:14:06.075979 140427498850176 efficientnet_model.py:147] round_filter input=32 output=48\n","I0129 17:14:06.095720 140427498850176 efficientnet_model.py:147] round_filter input=32 output=48\n","I0129 17:14:06.095859 140427498850176 efficientnet_model.py:147] round_filter input=16 output=24\n","I0129 17:14:06.253441 140427498850176 efficientnet_model.py:147] round_filter input=16 output=24\n","I0129 17:14:06.253651 140427498850176 efficientnet_model.py:147] round_filter input=24 output=32\n","I0129 17:14:06.652966 140427498850176 efficientnet_model.py:147] round_filter input=24 output=32\n","I0129 17:14:06.653248 140427498850176 efficientnet_model.py:147] round_filter input=40 output=56\n","I0129 17:14:07.063413 140427498850176 efficientnet_model.py:147] round_filter input=40 output=56\n","I0129 17:14:07.063614 140427498850176 efficientnet_model.py:147] round_filter input=80 output=112\n","I0129 17:14:07.645343 140427498850176 efficientnet_model.py:147] round_filter input=80 output=112\n","I0129 17:14:07.645538 140427498850176 efficientnet_model.py:147] round_filter input=112 output=160\n","I0129 17:14:08.232021 140427498850176 efficientnet_model.py:147] round_filter input=112 output=160\n","I0129 17:14:08.232259 140427498850176 efficientnet_model.py:147] round_filter input=192 output=272\n","I0129 17:14:09.009490 140427498850176 efficientnet_model.py:147] round_filter input=192 output=272\n","I0129 17:14:09.009697 140427498850176 efficientnet_model.py:147] round_filter input=320 output=448\n","I0129 17:14:09.465913 140427498850176 efficientnet_model.py:147] round_filter input=1280 output=1792\n","I0129 17:14:09.503260 140427498850176 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0129 17:14:09.600040 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0129 17:14:09.600265 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n","I0129 17:14:09.600378 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0129 17:14:09.602441 140427498850176 efficientnet_model.py:147] round_filter input=32 output=48\n","I0129 17:14:09.622156 140427498850176 efficientnet_model.py:147] round_filter input=32 output=48\n","I0129 17:14:09.622313 140427498850176 efficientnet_model.py:147] round_filter input=16 output=24\n","I0129 17:14:09.871716 140427498850176 efficientnet_model.py:147] round_filter input=16 output=24\n","I0129 17:14:09.871913 140427498850176 efficientnet_model.py:147] round_filter input=24 output=40\n","I0129 17:14:10.366214 140427498850176 efficientnet_model.py:147] round_filter input=24 output=40\n","I0129 17:14:10.366413 140427498850176 efficientnet_model.py:147] round_filter input=40 output=64\n","I0129 17:14:10.870358 140427498850176 efficientnet_model.py:147] round_filter input=40 output=64\n","I0129 17:14:10.870569 140427498850176 efficientnet_model.py:147] round_filter input=80 output=128\n","I0129 17:14:11.564901 140427498850176 efficientnet_model.py:147] round_filter input=80 output=128\n","I0129 17:14:11.565141 140427498850176 efficientnet_model.py:147] round_filter input=112 output=176\n","I0129 17:14:12.282579 140427498850176 efficientnet_model.py:147] round_filter input=112 output=176\n","I0129 17:14:12.282788 140427498850176 efficientnet_model.py:147] round_filter input=192 output=304\n","I0129 17:14:13.159401 140427498850176 efficientnet_model.py:147] round_filter input=192 output=304\n","I0129 17:14:13.159636 140427498850176 efficientnet_model.py:147] round_filter input=320 output=512\n","I0129 17:14:13.459602 140427498850176 efficientnet_model.py:147] round_filter input=1280 output=2048\n","I0129 17:14:13.494871 140427498850176 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0129 17:14:13.601273 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0129 17:14:13.601492 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0129 17:14:13.601617 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0129 17:14:13.603572 140427498850176 efficientnet_model.py:147] round_filter input=32 output=56\n","I0129 17:14:13.622424 140427498850176 efficientnet_model.py:147] round_filter input=32 output=56\n","I0129 17:14:13.622565 140427498850176 efficientnet_model.py:147] round_filter input=16 output=32\n","I0129 17:14:13.852593 140427498850176 efficientnet_model.py:147] round_filter input=16 output=32\n","I0129 17:14:13.852806 140427498850176 efficientnet_model.py:147] round_filter input=24 output=40\n","I0129 17:14:14.432221 140427498850176 efficientnet_model.py:147] round_filter input=24 output=40\n","I0129 17:14:14.432420 140427498850176 efficientnet_model.py:147] round_filter input=40 output=72\n","I0129 17:14:15.018646 140427498850176 efficientnet_model.py:147] round_filter input=40 output=72\n","I0129 17:14:15.018836 140427498850176 efficientnet_model.py:147] round_filter input=80 output=144\n","I0129 17:14:15.775819 140427498850176 efficientnet_model.py:147] round_filter input=80 output=144\n","I0129 17:14:15.776039 140427498850176 efficientnet_model.py:147] round_filter input=112 output=200\n","I0129 17:14:16.816373 140427498850176 efficientnet_model.py:147] round_filter input=112 output=200\n","I0129 17:14:16.816595 140427498850176 efficientnet_model.py:147] round_filter input=192 output=344\n","I0129 17:14:18.241572 140427498850176 efficientnet_model.py:147] round_filter input=192 output=344\n","I0129 17:14:18.241772 140427498850176 efficientnet_model.py:147] round_filter input=320 output=576\n","I0129 17:14:18.897957 140427498850176 efficientnet_model.py:147] round_filter input=1280 output=2304\n","I0129 17:14:18.949917 140427498850176 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0129 17:14:19.084141 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0129 17:14:19.084338 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0129 17:14:19.084450 140427498850176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0129 17:14:19.086553 140427498850176 efficientnet_model.py:147] round_filter input=32 output=64\n","I0129 17:14:19.105794 140427498850176 efficientnet_model.py:147] round_filter input=32 output=64\n","I0129 17:14:19.105933 140427498850176 efficientnet_model.py:147] round_filter input=16 output=32\n","I0129 17:14:19.415445 140427498850176 efficientnet_model.py:147] round_filter input=16 output=32\n","I0129 17:14:19.415657 140427498850176 efficientnet_model.py:147] round_filter input=24 output=48\n","I0129 17:14:20.443384 140427498850176 efficientnet_model.py:147] round_filter input=24 output=48\n","I0129 17:14:20.443591 140427498850176 efficientnet_model.py:147] round_filter input=40 output=80\n","I0129 17:14:21.143195 140427498850176 efficientnet_model.py:147] round_filter input=40 output=80\n","I0129 17:14:21.143418 140427498850176 efficientnet_model.py:147] round_filter input=80 output=160\n","I0129 17:14:22.112991 140427498850176 efficientnet_model.py:147] round_filter input=80 output=160\n","I0129 17:14:22.113297 140427498850176 efficientnet_model.py:147] round_filter input=112 output=224\n","I0129 17:14:23.104887 140427498850176 efficientnet_model.py:147] round_filter input=112 output=224\n","I0129 17:14:23.105109 140427498850176 efficientnet_model.py:147] round_filter input=192 output=384\n","I0129 17:14:24.681755 140427498850176 efficientnet_model.py:147] round_filter input=192 output=384\n","I0129 17:14:24.681960 140427498850176 efficientnet_model.py:147] round_filter input=320 output=640\n","I0129 17:14:25.087483 140427498850176 efficientnet_model.py:147] round_filter input=1280 output=2560\n","I0129 17:14:25.123514 140427498850176 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 29.03s\n","I0129 17:14:25.281740 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 29.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0129 17:14:25.289553 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0129 17:14:25.291845 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0129 17:14:25.292529 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0129 17:14:25.294445 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0129 17:14:25.296467 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0129 17:14:25.297043 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0129 17:14:25.298328 140427498850176 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 36.771s\n","\n","OK (skipped=1)\n"]}]},{"cell_type":"markdown","source":["training_demo/\n","├─ annotations/\n","├─ exported-models/\n","├─ images/\n","│  ├─ test/\n","│  └─ train/\n","├─ models/\n","├─ pre-trained-models/\n","└─ README.md"],"metadata":{"id":"lwhalUn3KIUU"}},{"cell_type":"code","source":["cd /content/training_demo/images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brLrlXb2J6Wl","executionInfo":{"status":"ok","timestamp":1643476505712,"user_tz":-330,"elapsed":607,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"33296514-7460-4245-9318-0639d4c28bc4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training_demo/images\n"]}]},{"cell_type":"code","source":["from zipfile import ZipFile"],"metadata":{"id":"CeXX3s2sJ6T1","executionInfo":{"status":"ok","timestamp":1643476508227,"user_tz":-330,"elapsed":322,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["file_ = '/content/drive/MyDrive/IDD_object_detection/train.zip'\n","with ZipFile(file_,'r') as x:\n","  x.extractall()"],"metadata":{"id":"VlomplgVJ6RZ","executionInfo":{"status":"ok","timestamp":1643476627614,"user_tz":-330,"elapsed":117841,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["cd /content/training_demo/images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NDD0HJD2J6Oe","executionInfo":{"status":"ok","timestamp":1643476650788,"user_tz":-330,"elapsed":367,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"e2bd7664-ddc4-460a-e37f-4193ee66e13d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training_demo/images\n"]}]},{"cell_type":"code","source":["file_test = '/content/drive/MyDrive/IDD_object_detection/test.zip'\n","with ZipFile(file_test,'r') as u:\n","  u.extractall()"],"metadata":{"id":"tV-CASKfJ6MD","executionInfo":{"status":"ok","timestamp":1643476653002,"user_tz":-330,"elapsed":461,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["cd /content/scripts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fFs8OHg2J6Jo","executionInfo":{"status":"ok","timestamp":1643476655593,"user_tz":-330,"elapsed":318,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"f665dd66-62d0-4d94-c330-c0661f71eaa7"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/scripts\n"]}]},{"cell_type":"code","source":["!python generate_tfrecord.py -x /content/training_demo/images/train -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/train.record"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYm_qL5RJ6HG","executionInfo":{"status":"ok","timestamp":1643476779499,"user_tz":-330,"elapsed":58479,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"8d686289-6494-45d8-fc91-ab0b698ce247"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecord file: /content/training_demo/annotations/train.record\n"]}]},{"cell_type":"code","source":["!python generate_tfrecord.py -x /content/training_demo/images/test -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/test.record"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9TMmb6HeJ6EU","executionInfo":{"status":"ok","timestamp":1643476788009,"user_tz":-330,"elapsed":5168,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"3660def7-a53c-4dea-99c9-665fb88cbda1"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecord file: /content/training_demo/annotations/test.record\n"]}]},{"cell_type":"code","source":["import requests\n","url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n","\n","path = 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'"],"metadata":{"id":"rNdK8JA2J6CJ","executionInfo":{"status":"ok","timestamp":1643476790717,"user_tz":-330,"elapsed":428,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["cd /content/training_demo/pre-trained-models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSRhDfvcJ5_e","executionInfo":{"status":"ok","timestamp":1643476796399,"user_tz":-330,"elapsed":415,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"83cc8789-3e5e-4163-e1f6-28aed3ea0e73"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training_demo/pre-trained-models\n"]}]},{"cell_type":"code","source":["response = requests.get(url, stream=True)\n","if response.status_code == 200:\n","    with open(path, 'wb') as f:\n","        f.write(response.raw.read())"],"metadata":{"id":"hjh7m4j8J582","executionInfo":{"status":"ok","timestamp":1643476801982,"user_tz":-330,"elapsed":2012,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["import tarfile\n","  \n","# open file\n","file = tarfile.open('ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz')\n","  \n","# extracting file\n","file.extractall()\n","  \n","file.close()"],"metadata":{"id":"--YSqNODJ56L","executionInfo":{"status":"ok","timestamp":1643476809423,"user_tz":-330,"elapsed":3327,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["cd /content/training_demo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fta7E7t5J53j","executionInfo":{"status":"ok","timestamp":1643476823366,"user_tz":-330,"elapsed":558,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"91f3fdb3-54e9-4bde-e15e-52278fecd698"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training_demo\n"]}]},{"cell_type":"code","source":["!pip install \"opencv-python-headless<4.3\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xETAa8iaO2iE","executionInfo":{"status":"ok","timestamp":1643477125223,"user_tz":-330,"elapsed":6979,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"cca36e1e-145a-4f6c-9800-7427969ad658"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opencv-python-headless<4.3\n","  Downloading opencv_python_headless-4.2.0.34-cp37-cp37m-manylinux1_x86_64.whl (21.6 MB)\n","\u001b[K     |████████████████████████████████| 21.6 MB 353 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless<4.3) (1.19.5)\n","Installing collected packages: opencv-python-headless\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.5.5.62\n","    Uninstalling opencv-python-headless-4.5.5.62:\n","      Successfully uninstalled opencv-python-headless-4.5.5.62\n","Successfully installed opencv-python-headless-4.2.0.34\n"]}]},{"cell_type":"code","source":["!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lijvAC3NOy5J","executionInfo":{"status":"error","timestamp":1643482769999,"user_tz":-330,"elapsed":5584779,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"0617c35d-4c33-48c7-d223-7a1cd5e52882"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-01-29 17:26:34.449368: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0129 17:26:34.480543 140383702615936 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0129 17:26:34.495618 140383702615936 config_util.py:552] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0129 17:26:34.495807 140383702615936 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0129 17:26:34.586117 140383702615936 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n","I0129 17:26:34.611420 140383702615936 dataset_builder.py:163] Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n","I0129 17:26:34.613884 140383702615936 dataset_builder.py:80] Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0129 17:26:34.614038 140383702615936 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0129 17:26:34.614208 140383702615936 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0129 17:26:34.634222 140383702615936 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0129 17:26:34.700716 140383702615936 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0129 17:26:43.707883 140383702615936 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0129 17:26:47.432496 140383702615936 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0129 17:26:49.522018 140383702615936 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2022-01-29 17:26:58.063016: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24883200 exceeds 10% of free system memory.\n","2022-01-29 17:26:58.125169: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24883200 exceeds 10% of free system memory.\n","2022-01-29 17:26:58.272487: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24883200 exceeds 10% of free system memory.\n","2022-01-29 17:26:58.290456: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24883200 exceeds 10% of free system memory.\n","2022-01-29 17:26:58.308883: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24883200 exceeds 10% of free system memory.\n","2022-01-29 17:26:58.774242: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0129 17:27:41.783053 140383702615936 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0129 17:27:41.784598 140383702615936 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0129 17:27:41.787482 140383702615936 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0129 17:27:41.788627 140383702615936 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0129 17:27:41.791638 140383702615936 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0129 17:27:41.792927 140383702615936 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0129 17:27:41.796302 140383702615936 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0129 17:27:41.797603 140383702615936 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0129 17:27:41.799859 140383702615936 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0129 17:27:41.801065 140383702615936 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0129 17:27:42.940119 140378883725056 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 3.234s\n","I0129 17:33:05.914269 140383702615936 model_lib_v2.py:707] Step 100 per-step time 3.234s\n","INFO:tensorflow:{'Loss/classification_loss': 0.4124072,\n"," 'Loss/localization_loss': 0.4186433,\n"," 'Loss/regularization_loss': 0.25241053,\n"," 'Loss/total_loss': 1.083461,\n"," 'learning_rate': 0.023999799}\n","I0129 17:33:05.920635 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.4124072,\n"," 'Loss/localization_loss': 0.4186433,\n"," 'Loss/regularization_loss': 0.25241053,\n"," 'Loss/total_loss': 1.083461,\n"," 'learning_rate': 0.023999799}\n","INFO:tensorflow:Step 200 per-step time 2.640s\n","I0129 17:37:29.840694 140383702615936 model_lib_v2.py:707] Step 200 per-step time 2.640s\n","INFO:tensorflow:{'Loss/classification_loss': 0.35609367,\n"," 'Loss/localization_loss': 0.3734126,\n"," 'Loss/regularization_loss': 0.25714597,\n"," 'Loss/total_loss': 0.98665226,\n"," 'learning_rate': 0.034666598}\n","I0129 17:37:29.841113 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.35609367,\n"," 'Loss/localization_loss': 0.3734126,\n"," 'Loss/regularization_loss': 0.25714597,\n"," 'Loss/total_loss': 0.98665226,\n"," 'learning_rate': 0.034666598}\n","INFO:tensorflow:Step 300 per-step time 2.639s\n","I0129 17:41:53.765744 140383702615936 model_lib_v2.py:707] Step 300 per-step time 2.639s\n","INFO:tensorflow:{'Loss/classification_loss': 0.48817426,\n"," 'Loss/localization_loss': 0.46199295,\n"," 'Loss/regularization_loss': 0.26292792,\n"," 'Loss/total_loss': 1.2130952,\n"," 'learning_rate': 0.039982457}\n","I0129 17:41:53.766187 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.48817426,\n"," 'Loss/localization_loss': 0.46199295,\n"," 'Loss/regularization_loss': 0.26292792,\n"," 'Loss/total_loss': 1.2130952,\n"," 'learning_rate': 0.039982457}\n","INFO:tensorflow:Step 400 per-step time 2.638s\n","I0129 17:46:17.527679 140383702615936 model_lib_v2.py:707] Step 400 per-step time 2.638s\n","INFO:tensorflow:{'Loss/classification_loss': 0.43989447,\n"," 'Loss/localization_loss': 0.46976835,\n"," 'Loss/regularization_loss': 0.26750147,\n"," 'Loss/total_loss': 1.1771643,\n"," 'learning_rate': 0.039842296}\n","I0129 17:46:17.528136 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.43989447,\n"," 'Loss/localization_loss': 0.46976835,\n"," 'Loss/regularization_loss': 0.26750147,\n"," 'Loss/total_loss': 1.1771643,\n"," 'learning_rate': 0.039842296}\n","INFO:tensorflow:Step 500 per-step time 2.638s\n","I0129 17:50:41.450861 140383702615936 model_lib_v2.py:707] Step 500 per-step time 2.638s\n","INFO:tensorflow:{'Loss/classification_loss': 0.37993816,\n"," 'Loss/localization_loss': 0.40938634,\n"," 'Loss/regularization_loss': 0.26829198,\n"," 'Loss/total_loss': 1.0576165,\n"," 'learning_rate': 0.03956295}\n","I0129 17:50:41.461238 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.37993816,\n"," 'Loss/localization_loss': 0.40938634,\n"," 'Loss/regularization_loss': 0.26829198,\n"," 'Loss/total_loss': 1.0576165,\n"," 'learning_rate': 0.03956295}\n","INFO:tensorflow:Step 600 per-step time 2.642s\n","I0129 17:55:05.532850 140383702615936 model_lib_v2.py:707] Step 600 per-step time 2.642s\n","INFO:tensorflow:{'Loss/classification_loss': 0.34026298,\n"," 'Loss/localization_loss': 0.34253845,\n"," 'Loss/regularization_loss': 0.26815122,\n"," 'Loss/total_loss': 0.95095265,\n"," 'learning_rate': 0.03914639}\n","I0129 17:55:05.533240 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.34026298,\n"," 'Loss/localization_loss': 0.34253845,\n"," 'Loss/regularization_loss': 0.26815122,\n"," 'Loss/total_loss': 0.95095265,\n"," 'learning_rate': 0.03914639}\n","INFO:tensorflow:Step 700 per-step time 2.638s\n","I0129 17:59:29.367715 140383702615936 model_lib_v2.py:707] Step 700 per-step time 2.638s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3734842,\n"," 'Loss/localization_loss': 0.3969888,\n"," 'Loss/regularization_loss': 0.26668638,\n"," 'Loss/total_loss': 1.0371594,\n"," 'learning_rate': 0.038595527}\n","I0129 17:59:29.368129 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.3734842,\n"," 'Loss/localization_loss': 0.3969888,\n"," 'Loss/regularization_loss': 0.26668638,\n"," 'Loss/total_loss': 1.0371594,\n"," 'learning_rate': 0.038595527}\n","INFO:tensorflow:Step 800 per-step time 2.638s\n","I0129 18:03:53.214245 140383702615936 model_lib_v2.py:707] Step 800 per-step time 2.638s\n","INFO:tensorflow:{'Loss/classification_loss': 0.35458967,\n"," 'Loss/localization_loss': 0.37352884,\n"," 'Loss/regularization_loss': 0.26525748,\n"," 'Loss/total_loss': 0.993376,\n"," 'learning_rate': 0.037914235}\n","I0129 18:03:53.214631 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.35458967,\n"," 'Loss/localization_loss': 0.37352884,\n"," 'Loss/regularization_loss': 0.26525748,\n"," 'Loss/total_loss': 0.993376,\n"," 'learning_rate': 0.037914235}\n","INFO:tensorflow:Step 900 per-step time 2.639s\n","I0129 18:08:17.104007 140383702615936 model_lib_v2.py:707] Step 900 per-step time 2.639s\n","INFO:tensorflow:{'Loss/classification_loss': 0.36138466,\n"," 'Loss/localization_loss': 0.42139202,\n"," 'Loss/regularization_loss': 0.2641418,\n"," 'Loss/total_loss': 1.0469184,\n"," 'learning_rate': 0.037107285}\n","I0129 18:08:17.104426 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.36138466,\n"," 'Loss/localization_loss': 0.42139202,\n"," 'Loss/regularization_loss': 0.2641418,\n"," 'Loss/total_loss': 1.0469184,\n"," 'learning_rate': 0.037107285}\n","INFO:tensorflow:Step 1000 per-step time 2.628s\n","I0129 18:12:39.892220 140383702615936 model_lib_v2.py:707] Step 1000 per-step time 2.628s\n","INFO:tensorflow:{'Loss/classification_loss': 0.33888882,\n"," 'Loss/localization_loss': 0.3927539,\n"," 'Loss/regularization_loss': 0.26383457,\n"," 'Loss/total_loss': 0.99547726,\n"," 'learning_rate': 0.03618034}\n","I0129 18:12:39.892635 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.33888882,\n"," 'Loss/localization_loss': 0.3927539,\n"," 'Loss/regularization_loss': 0.26383457,\n"," 'Loss/total_loss': 0.99547726,\n"," 'learning_rate': 0.03618034}\n","INFO:tensorflow:Step 1100 per-step time 2.647s\n","I0129 18:17:04.617275 140383702615936 model_lib_v2.py:707] Step 1100 per-step time 2.647s\n","INFO:tensorflow:{'Loss/classification_loss': 0.46824604,\n"," 'Loss/localization_loss': 0.3688506,\n"," 'Loss/regularization_loss': 0.2626345,\n"," 'Loss/total_loss': 1.0997311,\n"," 'learning_rate': 0.0351399}\n","I0129 18:17:04.617683 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.46824604,\n"," 'Loss/localization_loss': 0.3688506,\n"," 'Loss/regularization_loss': 0.2626345,\n"," 'Loss/total_loss': 1.0997311,\n"," 'learning_rate': 0.0351399}\n","INFO:tensorflow:Step 1200 per-step time 2.628s\n","I0129 18:21:27.369090 140383702615936 model_lib_v2.py:707] Step 1200 per-step time 2.628s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3070155,\n"," 'Loss/localization_loss': 0.33491787,\n"," 'Loss/regularization_loss': 0.26163602,\n"," 'Loss/total_loss': 0.90356946,\n"," 'learning_rate': 0.033993267}\n","I0129 18:21:27.369478 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.3070155,\n"," 'Loss/localization_loss': 0.33491787,\n"," 'Loss/regularization_loss': 0.26163602,\n"," 'Loss/total_loss': 0.90356946,\n"," 'learning_rate': 0.033993267}\n","INFO:tensorflow:Step 1300 per-step time 2.630s\n","I0129 18:25:50.418956 140383702615936 model_lib_v2.py:707] Step 1300 per-step time 2.630s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2720032,\n"," 'Loss/localization_loss': 0.33933964,\n"," 'Loss/regularization_loss': 0.25964215,\n"," 'Loss/total_loss': 0.87098503,\n"," 'learning_rate': 0.03274848}\n","I0129 18:25:50.419332 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.2720032,\n"," 'Loss/localization_loss': 0.33933964,\n"," 'Loss/regularization_loss': 0.25964215,\n"," 'Loss/total_loss': 0.87098503,\n"," 'learning_rate': 0.03274848}\n","INFO:tensorflow:Step 1400 per-step time 2.631s\n","I0129 18:30:13.471885 140383702615936 model_lib_v2.py:707] Step 1400 per-step time 2.631s\n","INFO:tensorflow:{'Loss/classification_loss': 0.29954898,\n"," 'Loss/localization_loss': 0.39671516,\n"," 'Loss/regularization_loss': 0.25723946,\n"," 'Loss/total_loss': 0.9535036,\n"," 'learning_rate': 0.03141427}\n","I0129 18:30:13.472293 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.29954898,\n"," 'Loss/localization_loss': 0.39671516,\n"," 'Loss/regularization_loss': 0.25723946,\n"," 'Loss/total_loss': 0.9535036,\n"," 'learning_rate': 0.03141427}\n","INFO:tensorflow:Step 1500 per-step time 2.628s\n","I0129 18:34:36.321442 140383702615936 model_lib_v2.py:707] Step 1500 per-step time 2.628s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2494636,\n"," 'Loss/localization_loss': 0.28692767,\n"," 'Loss/regularization_loss': 0.25473356,\n"," 'Loss/total_loss': 0.7911248,\n"," 'learning_rate': 0.03}\n","I0129 18:34:36.321891 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.2494636,\n"," 'Loss/localization_loss': 0.28692767,\n"," 'Loss/regularization_loss': 0.25473356,\n"," 'Loss/total_loss': 0.7911248,\n"," 'learning_rate': 0.03}\n","INFO:tensorflow:Step 1600 per-step time 2.630s\n","I0129 18:38:59.347949 140383702615936 model_lib_v2.py:707] Step 1600 per-step time 2.630s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3079825,\n"," 'Loss/localization_loss': 0.37304708,\n"," 'Loss/regularization_loss': 0.25260043,\n"," 'Loss/total_loss': 0.93363,\n"," 'learning_rate': 0.028515583}\n","I0129 18:38:59.348452 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.3079825,\n"," 'Loss/localization_loss': 0.37304708,\n"," 'Loss/regularization_loss': 0.25260043,\n"," 'Loss/total_loss': 0.93363,\n"," 'learning_rate': 0.028515583}\n","INFO:tensorflow:Step 1700 per-step time 2.630s\n","I0129 18:43:22.321140 140383702615936 model_lib_v2.py:707] Step 1700 per-step time 2.630s\n","INFO:tensorflow:{'Loss/classification_loss': 0.28112757,\n"," 'Loss/localization_loss': 0.3172803,\n"," 'Loss/regularization_loss': 0.2508012,\n"," 'Loss/total_loss': 0.8492091,\n"," 'learning_rate': 0.026971439}\n","I0129 18:43:22.321521 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.28112757,\n"," 'Loss/localization_loss': 0.3172803,\n"," 'Loss/regularization_loss': 0.2508012,\n"," 'Loss/total_loss': 0.8492091,\n"," 'learning_rate': 0.026971439}\n","INFO:tensorflow:Step 1800 per-step time 2.628s\n","I0129 18:47:45.115078 140383702615936 model_lib_v2.py:707] Step 1800 per-step time 2.628s\n","INFO:tensorflow:{'Loss/classification_loss': 0.26722172,\n"," 'Loss/localization_loss': 0.30476493,\n"," 'Loss/regularization_loss': 0.24891734,\n"," 'Loss/total_loss': 0.82090396,\n"," 'learning_rate': 0.025378397}\n","I0129 18:47:45.115484 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.26722172,\n"," 'Loss/localization_loss': 0.30476493,\n"," 'Loss/regularization_loss': 0.24891734,\n"," 'Loss/total_loss': 0.82090396,\n"," 'learning_rate': 0.025378397}\n","INFO:tensorflow:Step 1900 per-step time 2.628s\n","I0129 18:52:07.956281 140383702615936 model_lib_v2.py:707] Step 1900 per-step time 2.628s\n","INFO:tensorflow:{'Loss/classification_loss': 0.29142705,\n"," 'Loss/localization_loss': 0.38790423,\n"," 'Loss/regularization_loss': 0.24729674,\n"," 'Loss/total_loss': 0.926628,\n"," 'learning_rate': 0.023747627}\n","I0129 18:52:07.956685 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.29142705,\n"," 'Loss/localization_loss': 0.38790423,\n"," 'Loss/regularization_loss': 0.24729674,\n"," 'Loss/total_loss': 0.926628,\n"," 'learning_rate': 0.023747627}\n","INFO:tensorflow:Step 2000 per-step time 2.628s\n","I0129 18:56:30.739761 140383702615936 model_lib_v2.py:707] Step 2000 per-step time 2.628s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2381191,\n"," 'Loss/localization_loss': 0.2698942,\n"," 'Loss/regularization_loss': 0.2457722,\n"," 'Loss/total_loss': 0.7537855,\n"," 'learning_rate': 0.022090567}\n","I0129 18:56:30.740190 140383702615936 model_lib_v2.py:708] {'Loss/classification_loss': 0.2381191,\n"," 'Loss/localization_loss': 0.2698942,\n"," 'Loss/regularization_loss': 0.2457722,\n"," 'Loss/total_loss': 0.7537855,\n"," 'learning_rate': 0.022090567}\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-73d626c0c8b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    445\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m   result = _run_command(\n\u001b[0;32m--> 447\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    448\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;31m# TODO(b/115527726): Rather than sleep, poll for incoming messages from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;31m# the frontend in the same poll as for the output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["cd /content/training_demo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbLT6_DHQyyn","executionInfo":{"status":"ok","timestamp":1643482782045,"user_tz":-330,"elapsed":449,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"5bde44fd-8082-4ed9-e632-64d0f86a6133"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training_demo\n"]}]},{"cell_type":"code","source":["pwd #getting the current working directori"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Qt1nefmwVu_q","executionInfo":{"status":"ok","timestamp":1643482796277,"user_tz":-330,"elapsed":325,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"3328aa7f-81f5-4143-9055-ba378fd14ca0"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/training_demo'"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["#evaluating the model\n","!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config --checkpoint_dir=models/my_ssd_resnet50_v1_fpn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D-KebFbl6jUy","executionInfo":{"status":"ok","timestamp":1643483232489,"user_tz":-330,"elapsed":434361,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"a1c86bd3-2d16-4215-c974-0c8062ba2742"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0129 19:00:10.214935 140027091437440 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n","I0129 19:00:10.215253 140027091437440 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0129 19:00:10.215403 140027091437440 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0129 19:00:10.215564 140027091437440 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0129 19:00:10.215762 140027091437440 model_lib_v2.py:1111] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","2022-01-29 19:00:12.689168: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Reading unweighted datasets: ['/content/training_demo/annotations/test.record']\n","I0129 19:00:12.757636 140027091437440 dataset_builder.py:163] Reading unweighted datasets: ['/content/training_demo/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/training_demo/annotations/test.record']\n","I0129 19:00:12.758115 140027091437440 dataset_builder.py:80] Reading record datasets for input file: ['/content/training_demo/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0129 19:00:12.758278 140027091437440 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0129 19:00:12.758421 140027091437440 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0129 19:00:12.761379 140027091437440 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0129 19:00:12.821579 140027091437440 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0129 19:00:18.254753 140027091437440 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0129 19:00:19.636914 140027091437440 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Waiting for new checkpoint at models/my_ssd_resnet50_v1_fpn\n","I0129 19:00:23.137828 140027091437440 checkpoint_utils.py:140] Waiting for new checkpoint at models/my_ssd_resnet50_v1_fpn\n","INFO:tensorflow:Found new checkpoint at models/my_ssd_resnet50_v1_fpn/ckpt-3\n","I0129 19:00:23.139465 140027091437440 checkpoint_utils.py:149] Found new checkpoint at models/my_ssd_resnet50_v1_fpn/ckpt-3\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0129 19:01:05.957391 140027091437440 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Finished eval step 0\n","I0129 19:01:05.985054 140027091437440 model_lib_v2.py:966] Finished eval step 0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0129 19:01:06.205570 140027091437440 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Performing evaluation on 3 images.\n","I0129 19:01:08.921792 140027091437440 coco_evaluation.py:293] Performing evaluation on 3 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0129 19:01:08.922245 140027091437440 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0129 19:01:08.922740 140027091437440 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.04s).\n","Accumulating evaluation results...\n","DONE (t=0.06s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.331\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.207\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.639\n","INFO:tensorflow:Eval metrics at step 2000\n","I0129 19:01:09.032418 140027091437440 model_lib_v2.py:1015] Eval metrics at step 2000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.189255\n","I0129 19:01:09.035209 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.189255\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.330797\n","I0129 19:01:09.036971 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.330797\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.207012\n","I0129 19:01:09.038794 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.207012\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.021782\n","I0129 19:01:09.040632 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.021782\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.312561\n","I0129 19:01:09.042384 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.312561\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.404346\n","I0129 19:01:09.044240 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.404346\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.155625\n","I0129 19:01:09.046076 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.155625\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.291875\n","I0129 19:01:09.051347 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.291875\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.348750\n","I0129 19:01:09.053159 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.348750\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.021429\n","I0129 19:01:09.055069 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.021429\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.398958\n","I0129 19:01:09.056816 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.398958\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.639286\n","I0129 19:01:09.058645 140027091437440 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.639286\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.325171\n","I0129 19:01:09.060098 140027091437440 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.325171\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.396200\n","I0129 19:01:09.061576 140027091437440 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.396200\n","INFO:tensorflow:\t+ Loss/regularization_loss: 0.245752\n","I0129 19:01:09.063091 140027091437440 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.245752\n","INFO:tensorflow:\t+ Loss/total_loss: 0.967123\n","I0129 19:01:09.064483 140027091437440 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.967123\n","INFO:tensorflow:Waiting for new checkpoint at models/my_ssd_resnet50_v1_fpn\n","I0129 19:05:23.213252 140027091437440 checkpoint_utils.py:140] Waiting for new checkpoint at models/my_ssd_resnet50_v1_fpn\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n","    sys.exit(main(argv))\n","  File \"model_main_tf2.py\", line 90, in main\n","    wait_interval=300, timeout=FLAGS.eval_timeout)\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1137, in eval_continuously\n","    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 199, in checkpoints_iterator\n","    checkpoint_dir, checkpoint_path, timeout=timeout)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 147, in wait_for_new_checkpoint\n","    time.sleep(seconds_to_sleep)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"model_main_tf2.py\", line 115, in <module>\n","    tf.compat.v1.app.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 313, in run\n","    except UsageError as error:\n","KeyboardInterrupt\n"]}]},{"cell_type":"markdown","source":["exporting the model"],"metadata":{"id":"nc4Sxxok7PAb"}},{"cell_type":"code","source":["!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/training_demo/models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir /content/training_demo/models/my_ssd_resnet50_v1_fpn/ --output_directory /content/training_demo/exported-models/my_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TX1PwcdQyvh","executionInfo":{"status":"ok","timestamp":1643483321692,"user_tz":-330,"elapsed":83004,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"acaf3df3-9778-4293-a26a-6cc972978624"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-01-29 19:07:23.665094: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W0129 19:07:23.972700 140027495405440 deprecation.py:619] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f5a105522d0>, because it is not built.\n","W0129 19:07:49.523280 140027495405440 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f5a105522d0>, because it is not built.\n","2022-01-29 19:08:03.814965: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","W0129 19:08:29.702461 140027495405440 save.py:268] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: /content/training_demo/exported-models/my_model/saved_model/assets\n","I0129 19:08:38.854154 140027495405440 builder_impl.py:784] Assets written to: /content/training_demo/exported-models/my_model/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to /content/training_demo/exported-models/my_model/pipeline.config\n","I0129 19:08:39.705229 140027495405440 config_util.py:254] Writing pipeline config file to /content/training_demo/exported-models/my_model/pipeline.config\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Inferencing the trained object detection model (On Image) From TF2 Saved Model\n","\"\"\"\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n","import pathlib\n","import tensorflow as tf\n","import cv2\n","import argparse\n","from google.colab.patches import cv2_imshow\n","\n","# Enable GPU dynamic memory allocation\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)\n","\n","# PROVIDE PATH TO IMAGE DIRECTORY\n","IMAGE_PATHS = '/content/training_demo/images/train/0000149.jpg'\n","\n","\n","# PROVIDE PATH TO MODEL DIRECTORY\n","PATH_TO_MODEL_DIR = '/content/training_demo/exported-models/my_model'\n","\n","# PROVIDE PATH TO LABEL MAP\n","PATH_TO_LABELS = '/content/training_demo/annotations/label_map.pbtxt'\n","\n","# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n","MIN_CONF_THRESH = float(0.20)\n","\n","# LOAD THE MODEL\n","\n","import time\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n","\n","print('Loading model...', end='')\n","start_time = time.time()\n","\n","# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))\n","\n","# LOAD LABEL MAP DATA FOR PLOTTING\n","\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n","                                                                    use_display_name=True)\n","\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n","\n","def load_image_into_numpy_array(path):\n","    \"\"\"Load an image from file into a numpy array.\n","    Puts image into numpy array to feed into tensorflow graph.\n","    Note that by convention we put it into a numpy array with shape\n","    (height, width, channels), where channels=3 for RGB.\n","    Args:\n","      path: the file path to the image\n","    Returns:\n","      uint8 numpy array with shape (img_height, img_width, 3)\n","    \"\"\"\n","    return np.array(Image.open(path))\n","\n","\n","\n","\n","print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n","\n","image = cv2.imread(IMAGE_PATHS)\n","image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","image_expanded = np.expand_dims(image_rgb, axis=0)\n","\n","# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","input_tensor = tf.convert_to_tensor(image)\n","# The model expects a batch of images, so add an axis with `tf.newaxis`.\n","input_tensor = input_tensor[tf.newaxis, ...]\n","\n","# input_tensor = np.expand_dims(image_np, 0)\n","detections = detect_fn(input_tensor)\n","\n","# All outputs are batches tensors.\n","# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","# We're only interested in the first num_detections.\n","num_detections = int(detections.pop('num_detections'))\n","detections = {key: value[0, :num_detections].numpy()\n","               for key, value in detections.items()}\n","detections['num_detections'] = num_detections\n","\n","# detection_classes should be ints.\n","detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","image_with_detections = image.copy()\n","\n","# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_with_detections,\n","      detections['detection_boxes'],\n","      detections['detection_classes'],\n","      detections['detection_scores'],\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=200,\n","      min_score_thresh=0.5,\n","      agnostic_mode=False)\n","\n","print('Done')\n","# DISPLAYS OUTPUT IMAGE\n","cv2_imshow(image_with_detections)\n","# CLOSES WINDOW ONCE KEY IS PRESSED\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":863,"output_embedded_package_id":"1CxI9lfZoNLkda9lW9NOmyFr6tVIAbazN"},"id":"m374EZ25Qyse","executionInfo":{"status":"ok","timestamp":1643484340038,"user_tz":-330,"elapsed":29618,"user":{"displayName":"Vikas Nunna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMZx4b03dfsuT3d04xSIj1xGHh299-5LhXyxEA=s64","userId":"03476147915190095335"}},"outputId":"e0cad1ef-608b-40dc-c37b-bb6fc74bfdfd"},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["certainly our model is not performing well. With further training we can improve the performance of our model."],"metadata":{"id":"c4icgoIiiF2R"}},{"cell_type":"code","source":[""],"metadata":{"id":"3XfH3NUQh6n0"},"execution_count":null,"outputs":[]}]}